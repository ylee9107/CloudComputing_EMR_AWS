{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"s3://amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType, DateType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def run_stage1(datafile):\n",
    "    spark = SparkSession.builder.appName(\"COMP5349 Assignment 2\").getOrCreate()\n",
    "    \n",
    "    spark.conf.set(\"spark.sql.shuffle.partitions\", 20)\n",
    "    \n",
    "    reviews = spark.read.csv(datafile,header=True,sep='\\t').cache()\n",
    "    \n",
    "    review_count = str(reviews.count())\n",
    "\n",
    "    print(\"There are \" + review_count + \" reviews in total\")\n",
    "\n",
    "    distinct_user = str(reviews.select(\"customer_id\").distinct().count())\n",
    "\n",
    "    print(\"There are \" + distinct_user + \" unique users in total\")\n",
    "\n",
    "    distinct_product = str(reviews.select(\"product_id\").distinct().count())\n",
    "\n",
    "    print(\"There are \" + distinct_product + \" unique products in total\")\n",
    "\n",
    "    print(\"This is the largest number of reviews published by a single user: \")\n",
    "\n",
    "    reviews.groupBy(\"customer_id\").count().sort(\"count\", ascending=False).show(1)\n",
    "\n",
    "    print(\"This is the largest number of reviews published by the top 10 users: \")\n",
    "\n",
    "    reviews.groupBy(\"customer_id\").count().sort(\"count\", ascending=False).show(10)\n",
    "\n",
    "    print(\"This is the median number of reviews publish by a user: \")\n",
    "\n",
    "    median_rev_pub = reviews.groupBy(\"customer_id\").count().approxQuantile(\"Count\", [0.5], 0)[0]\n",
    "    print(median_rev_pub)\n",
    "\n",
    "    print(\"This is the largest number of reviews written for a single product: \")\n",
    "    reviews.groupBy(\"product_id\").count().sort(\"count\", ascending=False).show(1)\n",
    "\n",
    "    print(\"This is the largest number of reviews received by the top 10 products: \")\n",
    "    top10_products = reviews.groupBy(\"product_id\").count().sort(\"count\", ascending=False).limit(10)\n",
    "    top10_products.show()\n",
    "\n",
    "    print(\"This is the median number of reviews received by a product: \")\n",
    "    median_rev_rec = reviews.groupBy(\"product_id\").count().approxQuantile(\"Count\", [0.5], 0)[0]\n",
    "    print(median_rev_rec)\n",
    "\n",
    "    return median_rev_pub, median_rev_rec, top10_products.take(10), reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4751577 reviews in total\n",
      "There are 1940732 unique users in total\n",
      "There are 782326 unique products in total\n",
      "This is the largest number of reviews published by a single user: \n",
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|   50736950| 7168|\n",
      "+-----------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "This is the largest number of reviews published by the top 10 users: \n",
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|   50736950| 7168|\n",
      "|   38214553| 5412|\n",
      "|   51184997| 5369|\n",
      "|   18116317| 4222|\n",
      "|   23267387| 4023|\n",
      "|   50345651| 3793|\n",
      "|   14539589| 2896|\n",
      "|   15725862| 2842|\n",
      "|   19380211| 2592|\n",
      "|   20018062| 2568|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "This is the median number of reviews publish by a user: \n",
      "1.0\n",
      "This is the largest number of reviews written for a single product: \n",
      "+----------+-----+\n",
      "|product_id|count|\n",
      "+----------+-----+\n",
      "|B00008OWZG| 3936|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "This is the largest number of reviews received by the top 10 products: \n",
      "+----------+-----+\n",
      "|product_id|count|\n",
      "+----------+-----+\n",
      "|B00008OWZG| 3936|\n",
      "|B0000AGWEC| 3326|\n",
      "|B00MIA0KGY| 2699|\n",
      "|B00NEJ7MMI| 2420|\n",
      "|B000089RVX| 2376|\n",
      "|B004EBT5CU| 2106|\n",
      "|B0026P3G12| 2080|\n",
      "|B00009PRZF| 2026|\n",
      "|B00004XONN| 1901|\n",
      "|B00006J6VG| 1793|\n",
      "+----------+-----+\n",
      "\n",
      "This is the median number of reviews received by a product: \n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "median_rev_pub, median_rev_rec, top10_products, reviews = run_stage1(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as f\n",
    "import statistics\n",
    "import nltk\n",
    "\n",
    "def run_stage2(median_rev_pub, median_rev_rec, reviews):\n",
    "\n",
    "    def nltk_tokenizer(review_body):\n",
    "        return len(nltk.sent_tokenize(str(review_body)))\n",
    "\n",
    "    def median(n_list):\n",
    "        result = statistics.median(n_list)\n",
    "        return int(result)\n",
    "\n",
    "    # Define used defined function for sentence tokenizer\n",
    "    # This function takes a text column from sql and return integer column of number of sentences\n",
    "    sent_tokenizer = f.udf(nltk_tokenizer, IntegerType())\n",
    "\n",
    "    # keep only the below columns\n",
    "    keep_columns = ['customer_id', 'product_id', 'star_rating', 'review_id', 'review_body', 'review_sentences']\n",
    "\n",
    "    # Do sentence segmentation on review_body\n",
    "    filtered_reviews = reviews.withColumn('review_sentences', sent_tokenizer(reviews.review_body)).select(keep_columns)\n",
    "\n",
    "    # Keep only rows with review_body of 2 sentences and more\n",
    "    filtered_reviews = filtered_reviews.filter(\"review_sentences>=2\")\n",
    "\n",
    "    # Create a filter for user with more than median number of published reviews\n",
    "    filter1 = reviews.groupBy('customer_id').count().filter(\"count>\"+str(median_rev_pub)).drop('count')\n",
    "\n",
    "    # Create a fliter for products with more than median number of reviews recieved\n",
    "    filter2 = reviews.groupBy('product_id').count().filter('count>'+str(median_rev_rec)).drop('count')\n",
    "\n",
    "    # filter DataFrame using the above two filters\n",
    "    filtered_reviews = filtered_reviews.join(filter1, 'customer_id', 'inner').join(filter2, 'product_id', 'inner').cache()\n",
    "\n",
    "    # Top 10 users and products with highest median reviews\n",
    "    median_func = f.udf(median, IntegerType())\n",
    "    print('Top 10 users ranked by median number of sentences in the reviews they have published')\n",
    "    filtered_reviews.groupBy('customer_id').agg(median_func(f.collect_list(f.col('review_sentences'))).alias('median')).sort('median', ascending=False).show(10)\n",
    "\n",
    "    print('Top 10 products ranked by median number of sentences in the reviews they have received')\n",
    "    filtered_reviews.groupBy('product_id').agg(median_func(f.collect_list(f.col('review_sentences'))).alias('median')).sort('median', ascending=False).show(10)\n",
    "    return filtered_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 users ranked by median number of sentences in the reviews they have published\n",
      "+-----------+------+\n",
      "|customer_id|median|\n",
      "+-----------+------+\n",
      "|   25628286|   234|\n",
      "|   37118941|   227|\n",
      "|   51865782|   226|\n",
      "|   29580246|   201|\n",
      "|   50595705|   191|\n",
      "|   17821650|   183|\n",
      "|   43879820|   180|\n",
      "|   15585529|   177|\n",
      "|   23717536|   157|\n",
      "|   46097534|   154|\n",
      "+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Top 10 products ranked by median number of sentences in the reviews they have received\n",
      "+----------+------+\n",
      "|product_id|median|\n",
      "+----------+------+\n",
      "|B00LTQ5EVY|   984|\n",
      "|B009SF2GZU|   321|\n",
      "|B000003G29|   267|\n",
      "|B00T7TYTCK|   252|\n",
      "|B000BCH5PK|   209|\n",
      "|B0000C0FEW|   200|\n",
      "|B00AP5M4WM|   160|\n",
      "|B009SF2IRG|   157|\n",
      "|B008LA8E9K|   149|\n",
      "|B005ZHBBU6|   147|\n",
      "+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced_reviews = run_stage2(median_rev_pub, median_rev_rec, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0522 08:58:57.214910 140312044205888 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, ArrayType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "def review_embed(rev_text_partition):\n",
    "  module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "  embed = hub.Module(module_url)\n",
    "  # mapPartition would supply element inside a partition using generator stype\n",
    "  # this does not fit tensorflow stype\n",
    "  rev_text_list = [str(text) for text in rev_text_partition]  \n",
    "  if len(rev_text_list)==0:\n",
    "      return []\n",
    "  with tf.Session() as session:\n",
    "      session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "      message_embeddings = session.run(embed(rev_text_list))\n",
    "  return message_embeddings\n",
    "\n",
    "def run_stage3(reviews, product_rank, top10_products):\n",
    "    def nltk_tokenizer(review_body):\n",
    "        return nltk.sent_tokenize(str(review_body))\n",
    "  \n",
    "    def similarity_matrix(vector):\n",
    "        d = vector @ vector.T\n",
    "        norm = (vector * vector).sum(1, keepdims=True) ** .5\n",
    "        return 1 - d / norm / norm.T\n",
    "    \n",
    "    # Choose a product\n",
    "    product_id = top10_products[product_rank][0]\n",
    "\n",
    "    # Filter chosen product\n",
    "    reviews = reviews.filter(reviews.product_id==product_id)\n",
    "\n",
    "    # Sentence tokenizer function\n",
    "    sent_tokenizer = f.udf(nltk_tokenizer, ArrayType(StringType()))\n",
    "\n",
    "    reviews = reviews.filter(reviews.product_id==product_id)\n",
    "    # Extract positive reviews and tokenized\n",
    "    positive_reviews = reviews.filter('star_rating>3')\n",
    "    positive_reviews = positive_reviews.withColumn('tokenized_review_body', sent_tokenizer(positive_reviews.review_body))\n",
    "\n",
    "    # Extract negative reviews and tokenized\n",
    "    negative_reviews = reviews.filter('star_rating<3')\n",
    "\n",
    "    negative_reviews = negative_reviews.withColumn('tokenized_review_body', sent_tokenizer(negative_reviews.review_body))\n",
    "\n",
    "    # Positive Review body rdd\n",
    "    p_reviews_rdd = positive_reviews.select('review_id','tokenized_review_body').rdd.flatMapValues(lambda x: x).filter(lambda x: len(x[1])>0)\n",
    "    \n",
    "    # Negative Review body rdd\n",
    "    n_reviews_rdd = negative_reviews.select('review_id','tokenized_review_body').rdd.flatMapValues(lambda x: x).filter(lambda x: len(x[1])>0)\n",
    "    \n",
    "    positive_review_embedding = p_reviews_rdd.values().mapPartitions(review_embed).filter(lambda x: x != [])\n",
    "\n",
    "    negative_review_embedding = n_reviews_rdd.values().mapPartitions(review_embed).filter(lambda x: x != [])\n",
    "\n",
    "    # Intra-Class Similarity\n",
    "\n",
    "    p_vector = np.asarray(positive_review_embedding.collect())\n",
    "\n",
    "    npos = p_vector.shape[0]\n",
    "    \n",
    "    p_sim_matrix = similarity_matrix(p_vector)\n",
    "    \n",
    "    p_result = np.triu(p_sim_matrix).sum() / ((npos**2 - npos) / 2)\n",
    "\n",
    "    print('Average distance between sentences in the positive review class is '+str(p_result))\n",
    "\n",
    "    n_vector = np.asarray(negative_review_embedding.collect())\n",
    "\n",
    "    nneg = n_vector.shape[0]\n",
    "    \n",
    "    n_sim_matrix = similarity_matrix(n_vector)\n",
    "\n",
    "    n_result = np.triu(n_sim_matrix).sum() / ((nneg**2 - nneg) / 2)\n",
    "\n",
    "    print('Average distance between sentences in the negative review class is '+str(n_result))\n",
    "\n",
    "    # Class Center Sentences\n",
    "    p_avg_dist = p_sim_matrix.sum(axis=0) / npos\n",
    "    p_result = np.argsort(p_avg_dist)\n",
    "    p_reviews = p_reviews_rdd.collect()\n",
    "    print()\n",
    "    print('Positive center review_id and sentence:')\n",
    "    print(p_reviews[p_result[0]])\n",
    "    print()\n",
    "    print('Top 10 positive nearest review_ids and sentences')\n",
    "    for i in range(min(10, len(p_reviews) - 1)):\n",
    "        print(p_reviews[p_result[i + 1]])\n",
    "\n",
    "    n_avg_dist = n_sim_matrix.sum(axis=0) / npos\n",
    "    n_result = np.argsort(n_avg_dist)\n",
    "    n_reviews = n_reviews_rdd.collect()\n",
    "    print()\n",
    "    print('Negative center review_id and sentence:')\n",
    "    print(n_reviews[0])\n",
    "    print()\n",
    "    print('Top 10 positive nearest review_ids and sentences')\n",
    "    for i in range(min(10, len(n_reviews) - 1)):\n",
    "        print(n_reviews[n_result[i + 1]])\n",
    "\n",
    "    return p_reviews_rdd, n_reviews_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance between sentences in the positive review class is 0.6927572444366153\n",
      "Average distance between sentences in the negative review class is 0.7296461383763737\n",
      "\n",
      "Positive center review_id and sentence:\n",
      "('RWDRCB1IYL9QF', 'Every song is spectacular.')\n",
      "\n",
      "Top 10 positive nearest review_ids and sentences\n",
      "('R3M0H21UQDESQG', 'He definitely makes each song as a masterpiece.')\n",
      "('R2QFBOHT45UJ61', 'EVERY SONG IS AMAZING!')\n",
      "('R1XGIGOYF9XJ4B', 'THIS song along with most of the others is wonderful.')\n",
      "('R1C3Z0KW5J23KK', 'The entire selection of songs is phenomenal!')\n",
      "('R20RQCH1HEPG6T', \"This CD is a fantastic mix of ballads that show off Clay Aiken's powerful voice and some fun, up-tempo pop songs.\")\n",
      "('R1WDBTFIBQ603C', 'Every song is awesome!!')\n",
      "('RAPCBKXCGY1EE', \"The songs on this CD are all beautiful and all showcase Clay's magnificent voice.\")\n",
      "('R2W807APUY0UND', 'Every song is great!')\n",
      "('R2ZWUWVHROP1XL', 'The Way is another one of my favorite songs...')\n",
      "('R3O8ATGEQC1MN9', 'This Album is just great..I had a chance to listem to it and let me tell you.')\n",
      "\n",
      "Negative center review_id and sentence:\n",
      "('R2PCL2CCME6MUR', 'This CD disappointed me.')\n",
      "\n",
      "Top 10 positive nearest review_ids and sentences\n",
      "('RQBRSFPMVZK0Y', \"I know good music when I hear it and this debut by Clay Aiken isn't good music.\")\n",
      "('RQBC7WRI2E1X3', 'Put the lousy production of this album aside, he sings worse than an amateur.')\n",
      "('R299TJQO7YS4AR', 'This album is a MAJOR disappointment because Clay Aiken has so much promise as an entertainer.')\n",
      "('R30TKEAZEE9PIX', 'That a bad star for clay aiken this c-d is really borring and all the songs sound the same.')\n",
      "('R15661NEZUZBNU', 'The two stars are for this underachieving album, not for the man singing the trite songs which do not showcase his tremendous talent.<br />No ballads?')\n",
      "('R2TGS95HX3W9LQ', 'This CD is so unbelievably over hyped for a worthless collection of mediocre pop tunes sung by a mediocre singer who could not put emotion into a song if his life depended on it.<br />Total manufactured crap.')\n",
      "('RBQZYECJSGX7J', 'He needs to sing better songs than whats on this Cd.')\n",
      "('R2YOBI3D95D9UL', \"It is overproduced, oversung and a whole lot of crap.<BR>Clay can't even write his own songs.\")\n",
      "('R3OC2P07WWQX5Y', 'The record industry has given him bland mediocre midtempo songs that have no hook or anything special about them.')\n",
      "('R2HDX87SRM8PSD', \"Clay's voice is just fine, but this album takes no chances.\")\n"
     ]
    }
   ],
   "source": [
    "p_reviews_rdd, n_reviews_rdd = run_stage3(reduced_reviews, 1, top10_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType, ArrayType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "def run_stage4(positive_reviews, negative_reviews):      \n",
    "    def similarity_matrix(vector):\n",
    "        d = vector @ vector.T\n",
    "        norm = (vector * vector).sum(1, keepdims=True) ** .5\n",
    "        return 1 - d / norm / norm.T\n",
    "\n",
    "    row = Row('review_sentences')\n",
    "\n",
    "    positive_review_embedding = positive_reviews.values().map(lambda x: x.replace('.','').split(\" \")).map(row).toDF()\n",
    "\n",
    "    negative_review_embedding = negative_reviews.values().map(lambda x: x.replace('.','').split(\" \")).map(row).toDF()\n",
    "\n",
    "    word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"review_sentences\", outputCol=\"result\")\n",
    "\n",
    "    # Intra-Class Similarity\n",
    "    model = word2Vec.fit(positive_review_embedding)\n",
    "\n",
    "    result = model.transform(positive_review_embedding).collect()\n",
    "    p_vector = []\n",
    "    for row in result:\n",
    "        words, vector = row\n",
    "        p_vector.append(vector)\n",
    "    p_vector = np.asarray(p_vector)\n",
    "    npos = p_vector.shape[0]\n",
    "\n",
    "    p_sim_matrix = similarity_matrix(p_vector)\n",
    "        \n",
    "    p_result = np.triu(p_sim_matrix).sum() / ((npos**2 - npos) / 2)\n",
    "\n",
    "    print('Average distance between sentences in the positive review class is '+str(p_result))\n",
    "\n",
    "    model = word2Vec.fit(negative_review_embedding)\n",
    "\n",
    "    result = model.transform(negative_review_embedding).collect()\n",
    "\n",
    "    n_vector = []\n",
    "    for row in result:\n",
    "        words, vector = row\n",
    "        n_vector.append(vector)\n",
    "    n_vector = np.asarray(n_vector)\n",
    "\n",
    "    nneg = n_vector.shape[0]\n",
    "\n",
    "    n_sim_matrix = similarity_matrix(n_vector)\n",
    "        \n",
    "    n_result = np.triu(n_sim_matrix).sum() / ((nneg**2 - nneg) / 2)\n",
    "\n",
    "    print('Average distance between sentences in the negative review class is '+str(n_result))\n",
    "\n",
    "    # Class Center Sentences\n",
    "    p_avg_dist = p_sim_matrix.sum(axis=0) / npos\n",
    "    p_result = np.argsort(p_avg_dist)\n",
    "    p_reviews = p_reviews_rdd.collect()\n",
    "    print()\n",
    "    print('Positive center review_id and sentence:')\n",
    "    print(p_reviews[p_result[0]])\n",
    "    print()\n",
    "    print('Top 10 positive nearest review_ids and sentences')\n",
    "    for i in range(min(10, len(p_reviews) - 1)):\n",
    "        print(p_reviews[p_result[i + 1]])\n",
    "      \n",
    "    n_avg_dist = n_sim_matrix.sum(axis=0) / npos\n",
    "    n_result = np.argsort(n_avg_dist)\n",
    "    n_reviews = n_reviews_rdd.collect()  \n",
    "    print()\n",
    "    print('Negative center review_id and sentence:')\n",
    "    print(n_reviews[0])\n",
    "    print()\n",
    "    print('Top 10 positive nearest review_ids and sentences')\n",
    "    for i in range(min(10, len(n_reviews) - 1)):\n",
    "        print(n_reviews[n_result[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance between sentences in the positive review class is 0.6769896046767968\n",
      "Average distance between sentences in the negative review class is 0.23678240710413384\n",
      "\n",
      "Positive center review_id and sentence:\n",
      "('R25G8UWZF7PHBF', '<br /> <br />HOWEVER....this cd is mostly boring and the songs aren\\'t too special....as other reviewers have said, the problem with this cd is that all the songs sound pretty much the same....and IT DOES NOT show off Clay\\'s voice at all....the songs are poorly written and boring....I am really disappointed by Clay\\'s vocal performance as well because it\\'s just not good....not enough power and the quality of his voice is quite...rough....nothing like the beautiful voice that you hear in \\\\\\\\\"Solitaire\\\\\\\\\" and his Christmas Album.... <br /> <br />One thing though, is that this cd really grows on you...after listening to this cd a few times, I started to like it more cuz the song seems to be a bit addictive, ahaha....overall~not bad, pretty good....but it could be a lot better <br /> <br />Clay needs a cd with songs that can actually show off his voice....he seriously needs it...please no more of this \\\\\\\\\"boyband pop\\\\\\\\\"..... <br />and ino ppl will hate me for saying this but I don\\'t like \\\\\\\\\"Invisible\\\\\\\\\" because Clay just doesn\\'t sing it well...doesn\\'t sing with his diaphragm and lacks the strength.....this cd has pretty poor performance except for \\\\\\\\\"Measure of a Man\\\\\\\\\"..... <br />other than that song...i think this cd is pretty boring....no special performance by him....i\\'m starting to wonder how this cd became 3X platinum......... <br />Don\\'t take me wrong though, i\\'m a huge Clay fan.')\n",
      "\n",
      "Top 10 positive nearest review_ids and sentences\n",
      "('R3HLSKZKRZQ8WY', 'There is integrity in the album itself, and I think he has a right to be proud of it.')\n",
      "('R1G26Q66NTGK4U', \"As Clay said, use them for coasters because after listening to this CD and the lame lyrics, that is about all it's good for, no wonder he finished the CD in a month.....totally useless.\")\n",
      "('R19YCTNZ4R791K', \"I will buy this guys stuff from now on, he is an impressive young man on and off the stage, and I'm pround to say he's a good example for young people today...\")\n",
      "('R1S0WJL0Z6P85T', \"At first my favorite was 'No More Sad Song' (his voice just sounds so rich on that song) then it was 'Perfect Day' (another wonderful showcase for his beautiful voice) then it was 'Touch' (one of the most poetic and sensual songs I've ever heard; if you use your imagination while you listen to that song, you will drive yourself crazy) and today my favorite is 'The Way' (I think this could become a Number 1 song for weeks, maybe months!).\")\n",
      "('R2KF4EAUK5GZNL', \"My daughter eagerly anticipated the release of Clays CD, and I must admit I'm hooked as well--How refreshing it is to have a young pop star that [doesn't use] vulgar lyrics,condone violence, drugs, etc... or has sold out!\")\n",
      "('RIC6KICH3MH48', \"Clay has some great love ballads on this cd I am sure will go to #1.This is a great debut album,and anyone who does not see that, doesn't understand the type of singer that Clay is.Every song on this cd fit Clay's voice perfectly.This cd is just what I expected Clive Davis to do with it.Clay has his own sound and he doen't sound like anyone else.This cd marks the beginning of a legend.CONGRATULATIONS CLAY,YOU DID IT!!!!!\")\n",
      "('R2D378AF5VDO05', '<br />Clay just released his first single &quot;Invisible&quot; which is about my 4th or 5th favourite, but for those who really want to hear something with range, feeling, and just a great song in general, make sure you listen to &quot;Measure of a Man&quot; it is the best song on the cd.')\n",
      "('R2AE5ZHSDHOZSL', 'I suspect that if Clay or an actually good producer were in charge, we\\'d have a different album here.<br />Still, Clay\\'s voice is great, and this more than makes up for the overproduction and bad songwriting (btw, whatis all of this against a \\\\\\\\\"Broadway\\\\\\\\\" voice?')\n",
      "('R238WEI39RMP09', \"Just to start things off, I was never really a huge Clay Aiken fan to begin with.I had known his voice was good, but never really got into the songs from American Idol.This album changes everything I thought about him.And just to note, I'm no teenage girl, mind you: I'm a 14-year old teen guy, and it's not exactly everyday I run into a rarity of an album as this.To have an album so clean lyrically, uplifting songs, and a superb voice is truly a gift from God.Some personal favorites from this album are..well, all of them!\")\n",
      "('R1MY8S6QZXCGH4', 'For an album more like what I wish they had let Clay do check out the amazing &quot;For You&quot; by Jonathan Pierce - awesome voice, great songs, outstanding production and a terrific message.')\n",
      "\n",
      "Negative center review_id and sentence:\n",
      "('R2PCL2CCME6MUR', 'This CD disappointed me.')\n",
      "\n",
      "Top 10 positive nearest review_ids and sentences\n",
      "('R2FSQ54A9FY54R', \"clay has a nice voice, but all of his music sound a like, of course his fan's don't think so, even if it sounded horrible they would buy it.\")\n",
      "('R2I1HKGH35PIKN', 'Maybe in a year or so, if your opinion changes, you could do it again, but posting the same review about 10 times is just stupid.')\n",
      "('R2NCOL30RBWOBS', \"I almost feel like someone is just handing him a sheet of music, kicking on a recorder and saying &quot;Sing this.&quot;<br />Now this &quot;personal touch&quot; that I feel the album sorely lacked could have been caused by (or at least wasn't helped by) lyrics that, I felt, were extremely bland.\")\n",
      "('R1MY6NRNA15436', \"Measure of a man just doesn't do it for me.<BR>Sorry Clay, this one flopped.\")\n",
      "('R28Q5GPF1LB1DI', 'Amateur songwriters at RCA must be stamping out hit songs by the thousands, all with cliched lyrics.. Now they can stamp out pop stars who have nothing to say and no reason to be famous.')\n",
      "('R1PF0247UGRHQ2', \"Slipknot's VOL.#3 THE SUBLIMINAL VERSES (If you want something a lil' bit new check this disc out because yes even a Slipknot album is WAY better then this piece of rhyno's crap.<br />From, David Martera<br />P.S.\")\n",
      "('R1S18PRF5ZFLLR', 'I think a lot of people are buying this CD and making a lot of hype because they are glad to see someone who does not fit the mold make it big.')\n",
      "('RV0G140XZGTB', \"I'm sure many will argue with me about the title, but I'll stand by what I said.\")\n",
      "('R14LKFMV95M933', 'Here is a response from a radio station:<br />QUOTE:  \\\\\\\\\"As of right now, we have no plans to add &quot;Invisible&quot; to our playlist.<BR>Interest in the song is strictly limited to fans of Clay Aiken.<BR>People outside the &quot;Claymate&quot; realm really aren\\'t that into the song.<BR>The video isn\\'t even getting substantial play on MTV or VH-1.<BR>You may want to try our sister station.<BR>The song has more of an Adult Contemporary feel to it.<BR>Good luck!\\\\\\\\\" END OF QUOTE<br />Don\\'t believe all the five star reviews of this album, if you want true reviews of this album read the 3 to 1 star reviews and you will get a fair assessment of what it really is about.')\n",
      "('R188UKZBG55H5K', 'Here is a response from a radio station:<br />QUOTE:  \\\\\\\\\"As of right now, we have no plans to add &quot;Invisible&quot; to our playlist.<BR>Interest in the song is strictly limited to fans of Clay Aiken.<BR>People outside the &quot;Claymate&quot; realm really aren\\'t that into the song.<BR>The video isn\\'t even getting substantial play on MTV or VH-1.<BR>You may want to try our sister station.<BR>The song has more of an Adult Contemporary feel to it.<BR>Good luck!\\\\\\\\\" END OF QUOTE<br />Don\\'t believe all the five star reviews of this album, if you want true reviews of this album read the 3 to 1 star reviews and you will get a fair assessment of what it really is about.')\n"
     ]
    }
   ],
   "source": [
    "run_stage4(p_reviews_rdd, n_reviews_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
